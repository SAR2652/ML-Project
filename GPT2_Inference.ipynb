{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2 Inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a9c54c589d341388f35ba183ab17f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c04dde475d9c4caebdfc65b7dea97e6d",
              "IPY_MODEL_7ad6f912d40d4fbab63eed1b7c5edc14",
              "IPY_MODEL_441c4e7dd99347d49a674af82106d848"
            ],
            "layout": "IPY_MODEL_098fff30bc264404a9c96dc44a0ca701"
          }
        },
        "c04dde475d9c4caebdfc65b7dea97e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7dc75803c3c49b196724d0f5b69dc8b",
            "placeholder": "​",
            "style": "IPY_MODEL_b34386a6ccab4b6dbfb5828292fb732f",
            "value": "100%"
          }
        },
        "7ad6f912d40d4fbab63eed1b7c5edc14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce3eef5272f844549569f44872b8b89e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_400ec98026634296a604ffc860a19527",
            "value": 1
          }
        },
        "441c4e7dd99347d49a674af82106d848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_845f094c095f4d42aea16d4e05ca317a",
            "placeholder": "​",
            "style": "IPY_MODEL_2fa977e10c6e47a7899693afe6e5a3de",
            "value": " 1/1 [00:00&lt;00:00, 21.13it/s]"
          }
        },
        "098fff30bc264404a9c96dc44a0ca701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7dc75803c3c49b196724d0f5b69dc8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34386a6ccab4b6dbfb5828292fb732f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce3eef5272f844549569f44872b8b89e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "400ec98026634296a604ffc860a19527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "845f094c095f4d42aea16d4e05ca317a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fa977e10c6e47a7899693afe6e5a3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAR2652/ML-Project/blob/main/GPT2_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8Btll_V3ky5",
        "outputId": "233cd97f-fa03-4be5-d42c-cc2f01ad1366"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_-93BmOzL80",
        "outputId": "489ecddb-02b6-46d1-d90b-813501454658"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "from datasets import load_dataset\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import os"
      ],
      "metadata": {
        "id": "H_-6I_Ae4bC_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_special_tokens():\n",
        "\t\"\"\" Returns GPT2 tokenizer after adding separator and padding tokens \"\"\"\n",
        "\ttokenizer = GPT2Tokenizer.from_pretrained('gpt2', model_max_length = 1024)\n",
        "\tspecial_tokens = {'pad_token':'<|pad|>','sep_token':'<|sep|>'}\n",
        "\tnum_add_toks = tokenizer.add_special_tokens(special_tokens)\n",
        "\treturn tokenizer\n",
        "\n",
        "tokenizer = add_special_tokens()"
      ],
      "metadata": {
        "id": "j1d4dO0_y_VI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_path = '/content/drive/MyDrive/NYU courses/Sem 2/ML/Project/ml_data'\n",
        "data_path = '/content/drive/My Drive/test_data'\n",
        "# data_path = '/content/drive/MyDrive/validation'\n",
        "data = load_dataset(data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "7a9c54c589d341388f35ba183ab17f48",
            "c04dde475d9c4caebdfc65b7dea97e6d",
            "7ad6f912d40d4fbab63eed1b7c5edc14",
            "441c4e7dd99347d49a674af82106d848",
            "098fff30bc264404a9c96dc44a0ca701",
            "d7dc75803c3c49b196724d0f5b69dc8b",
            "b34386a6ccab4b6dbfb5828292fb732f",
            "ce3eef5272f844549569f44872b8b89e",
            "400ec98026634296a604ffc860a19527",
            "845f094c095f4d42aea16d4e05ca317a",
            "2fa977e10c6e47a7899693afe6e5a3de"
          ]
        },
        "id": "FXEJFZCy9jyP",
        "outputId": "6b395452-8d5e-441e-c895-1b603ff86786"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration test_data-6307297f2be303ed\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/test_data-6307297f2be303ed/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a9c54c589d341388f35ba183ab17f48"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MathQAData(Dataset):  \n",
        "    def __init__(self, control_code, tokenizer, max_length=1024):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.problems = self.tokenizer(control_code['Problem'])\n",
        "\n",
        "        self.rationales = []\n",
        "        for item in control_code['Rationale']:\n",
        "            self.rationales.append(self.tokenizer.encode(item))\n",
        "        \n",
        "        self.max_length = max_length\n",
        "        self.count = len(self.problems['input_ids'])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.count\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        example = dict()\n",
        "        text = self.tokenizer.encode(self.tokenizer.pad_token)*self.max_length\n",
        "        content = self.problems['input_ids'][idx] + self.tokenizer.encode(self.tokenizer.sep_token) + self.rationales[idx]\n",
        "        text[:len(content)] = content\n",
        "        text = torch.tensor(text)\n",
        "        example['article'] = text\n",
        "        example['sum_idx'] = len(self.problems['input_ids'][idx])\n",
        "        return example\n",
        "\n",
        "dataset = MathQAData(data['test'][:10], tokenizer) \n"
      ],
      "metadata": {
        "id": "zxjxfw2MAD_G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pReLCCzRSc0_",
        "outputId": "6ecaf651-c24c-439c-aed0-866a59090dc1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.resize_token_embeddings(len(tokenizer)) # VERY IMPORTANT\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/ml_models/gpt2_full_epoch_5.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqd6iLGMQ5kY",
        "outputId": "85c35615-5c73-4551-ae22-ff441d52dbfc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "\n",
        "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
        "    top_k = min(top_k, logits.size(-1))\n",
        "    if top_k > 0:\n",
        "        # Remove all tokens with a probability less than the last token of the top-k\n",
        "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
        "        logits[indices_to_remove] = filter_value\n",
        "\n",
        "    if top_p > 0.0:\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "        # Remove tokens with cumulative probability above the threshold\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "        # Shift the indices to the right to keep also the first token above the threshold\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "        logits[indices_to_remove] = filter_value\n",
        "    return logits\n",
        "\n",
        "\n",
        "def sample_seq(model, context, length, device, temperature=1, top_k=0, top_p=0.0):\n",
        "    \"\"\"\n",
        "    Generates rationale which is a sequence of tokens \n",
        "        Args:\n",
        "            model: gpt/gpt2 model\n",
        "            context: tokenized text using gpt/gpt2 tokenizer\n",
        "            length: length of generated sequence.\n",
        "            device: torch.device object.\n",
        "            temperature >0: used to control the randomness of predictions by scaling the logits before applying softmax.\n",
        "            top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n",
        "            top_p > 0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
        "    \"\"\"\n",
        "    \n",
        "    context = torch.tensor(context, dtype=torch.long, device=device)\n",
        "    context = context.unsqueeze(0)\n",
        "    generated = context\n",
        "    with torch.no_grad():  \n",
        "        for _ in trange(length):\n",
        "            inputs = {'input_ids': generated}\n",
        "            outputs = model(**inputs) \n",
        "            next_token_logits = outputs[0][0, -1, :] / temperature\n",
        "            filtered_logits = top_k_top_p_filtering(next_token_logits, top_k=top_k, top_p=top_p)\n",
        "            next_token = torch.multinomial(F.softmax(filtered_logits, dim=-1), num_samples=1)\n",
        "            generated = torch.cat((generated, next_token.unsqueeze(0)), dim=1)\n",
        "    return generated\n",
        "\n",
        "def generate_sample(data, tokenizer, model, num=1, eval_step=False, length=100, temperature=1, top_k=10, top_p=0.5, device=torch.device('cuda')):\n",
        "    \"\"\"\n",
        "    Generate rationales for \"num\" number of problems.\n",
        "    \"\"\"\n",
        "    for i in range(num):\n",
        "        sample = data[i]\n",
        "        idx = sample['sum_idx']\n",
        "        context = sample['article'][:idx].tolist()\n",
        "        summary = sample['article'][idx+1:][:100].tolist()\n",
        "        generated_text = sample_seq(model, context, length, device, temperature, top_k, top_p)\n",
        "        generated_text = generated_text[:].tolist()\n",
        "        # text = tokenizer.convert_ids_to_tokens(generated_text[0],skip_special_tokens=True)\n",
        "        text = [tokenizer.decode(id) for id in generated_text][0]\n",
        "        print(\"text is \", text)\n",
        "        # text = tokenizer.convert_tokens_to_string(text)\n",
        "        if eval_step==False:\n",
        "            print('new_article', end='\\n\\n')\n",
        "            print(tokenizer.decode(context), end='\\n\\n')\n",
        "            print(\"generated_summary\", end='\\n\\n')\n",
        "            print(text, end='\\n\\n')\n",
        "            print('actual_summary', end='\\n\\n')\n",
        "            print(tokenizer.decode(summary), end='\\n\\n')\n",
        "        else:\n",
        "            print(tokenizer.decode(context), end='\\n\\n')\n",
        "            print(\"generated_summary\", end='\\n\\n')"
      ],
      "metadata": {
        "id": "Y0Ib1aEbP1xh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "DD8oPcBRYAu7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = MathQAData(data['test'], tokenizer)"
      ],
      "metadata": {
        "id": "BWqqJGg1JB18"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "metadata": {
        "id": "dKcWMZLDLLb4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_scores = []\n",
        "for i in range(full_dataset.__len__()):\n",
        "    sample = full_dataset.__getitem__(i)\n",
        "    idx = sample['sum_idx']\n",
        "    context = sample['article'][:idx].tolist()\n",
        "    ref = data['test']['Rationale'][i]\n",
        "    summary = sample['article'][idx+1:][:100].tolist()\n",
        "    generated_text = sample_seq(model, context, 500, device)\n",
        "    generated_text = generated_text[:].tolist()\n",
        "    text = [tokenizer.decode(id) for id in generated_text][0]\n",
        "    bleu_scores.append(sentence_bleu(ref, text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj7kAfaXJ3dg",
        "outputId": "f1d91660-a9c9-49df-a92c-3b9768c0d58c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:09<00:00, 50.98it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.19it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.83it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.06it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.84it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.02it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 47.79it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.88it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.59it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 53.02it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.75it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.25it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.31it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 47.10it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.95it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.37it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.97it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.39it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.06it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.26it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.39it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.31it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.97it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.52it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.13it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.74it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 53.29it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.22it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.82it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.91it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 47.68it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.76it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.19it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.64it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.61it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 53.30it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.41it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.68it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.21it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 46.79it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.54it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.41it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.90it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.68it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.52it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.25it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.46it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 47.88it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.59it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.57it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.43it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.13it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.38it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.06it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.89it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.23it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.13it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.69it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.42it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.72it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.49it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 53.09it/s]\n",
            "100%|██████████| 500/500 [00:11<00:00, 45.30it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.50it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.43it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.40it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.38it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.68it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 46.62it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.17it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.06it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.26it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.62it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.05it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.08it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 46.58it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.00it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.39it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.81it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 46.55it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 47.53it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.08it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.69it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.59it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.77it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.98it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.03it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.67it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 46.80it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.74it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.72it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.17it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.24it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 47.79it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.03it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.24it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 47.81it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.50it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 45.59it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.16it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.32it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.84it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.03it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.07it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.21it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.63it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.95it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.76it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.38it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.40it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.68it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.54it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.90it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.73it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.56it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.14it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.67it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.66it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 47.79it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.48it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.41it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 46.26it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.51it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.33it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.42it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.95it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.13it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.08it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.32it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.74it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 46.60it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 53.06it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.63it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.19it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.64it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.02it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.19it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.58it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.71it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.72it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.20it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 53.67it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 53.63it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.13it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.61it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.25it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.65it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.72it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.40it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.66it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 53.26it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.50it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.31it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.95it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.36it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.73it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.55it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.62it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 46.82it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 47.02it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.85it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.00it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.31it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.09it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.31it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.67it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.14it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.06it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.48it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.13it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.91it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.53it/s]\n",
            "100%|██████████| 500/500 [00:15<00:00, 32.84it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.68it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.24it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.72it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 47.99it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.69it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.75it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.30it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.30it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.60it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.28it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.87it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.12it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.48it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 53.22it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.46it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.43it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.38it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.45it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.97it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.85it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.92it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.43it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.23it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.11it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.82it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.68it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.42it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.65it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 53.47it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.09it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.12it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.74it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.12it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 47.56it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.41it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.05it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.20it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.07it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 53.30it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 53.57it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.05it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 53.49it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.38it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 46.12it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.60it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.05it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.02it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.80it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 50.39it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 49.23it/s]\n",
            "100%|██████████| 500/500 [00:10<00:00, 48.31it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.51it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.67it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.05it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.71it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.05it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.96it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.09it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.92it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.84it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.80it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.21it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.86it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.37it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.16it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.18it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.54it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.33it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.81it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.07it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.27it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.24it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 52.76it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.89it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.33it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.91it/s]\n",
            "100%|██████████| 500/500 [00:09<00:00, 51.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "statistics.mean(bleu_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJW86YgPMGzt",
        "outputId": "8b73eb71-0c14-44fa-9efe-61bcc47dc18f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3243642351911246"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}